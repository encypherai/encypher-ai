{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EncypherAI Basic Usage\n",
    "\n",
    "This notebook demonstrates the basic usage of EncypherAI for encoding and decoding metadata in text.\n",
    "\n",
    "EncypherAI allows you to embed invisible metadata in text using Unicode variation selectors, making it perfect for tracking the provenance of LLM-generated content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install the EncypherAI package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Uncomment to install\n",
    "# !pip install encypher-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Encoding and Decoding\n",
    "\n",
    "Let's start with the basic encoding and decoding functionality using the `UnicodeMetadata` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from encypher.core.unicode_metadata import UnicodeMetadata, MetadataTarget\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a sample text that will have metadata embedded in it.\"\n",
    "\n",
    "# Metadata to embed\n",
    "model_id = \"gpt-4\"\n",
    "timestamp = datetime.now(timezone.utc).isoformat()\n",
    "custom_metadata = {\n",
    "    \"request_id\": \"req_12345\",\n",
    "    \"user_id\": \"user_6789\",\n",
    "    \"cost\": 0.0023\n",
    "}\n",
    "\n",
    "# Embed metadata\n",
    "encoded_text = UnicodeMetadata.embed_metadata(\n",
    "    text=text,\n",
    "    model_id=model_id,\n",
    "    timestamp=timestamp,\n",
    "    target=MetadataTarget.WHITESPACE,  # Can also use \"whitespace\" as string\n",
    "    custom_metadata=custom_metadata\n",
    ")\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(\"\\nEncoded text (looks the same but contains metadata):\")\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's extract the metadata from the encoded text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract metadata\n",
    "extracted_metadata = UnicodeMetadata.extract_metadata(encoded_text)\n",
    "\n",
    "print(\"Extracted metadata:\")\n",
    "for key, value in extracted_metadata.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the MetadataEncoder\n",
    "\n",
    "For more advanced use cases, you can use the `MetadataEncoder` class, which provides HMAC verification to ensure data integrity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from encypher.core.metadata_encoder import MetadataEncoder\n",
    "import json\n",
    "\n",
    "# Initialize encoder with a secret key\n",
    "encoder = MetadataEncoder(secret_key=\"your-secret-key\")\n",
    "\n",
    "# Sample text\n",
    "text = \"This text will have metadata embedded with HMAC verification.\"\n",
    "\n",
    "# Metadata to embed\n",
    "metadata = {\n",
    "    \"model_id\": \"gpt-4\",\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"request_id\": \"req_12345\",\n",
    "    \"user_id\": \"user_6789\",\n",
    "    \"cost\": 0.0023\n",
    "}\n",
    "\n",
    "# Encode metadata\n",
    "encoded_text = encoder.encode_metadata(text, metadata)\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(\"\\nEncoded text (looks the same but contains metadata with HMAC):\")\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify and decode the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verify and decode metadata\n",
    "is_valid, extracted_metadata, clean_text = encoder.verify_text(encoded_text)\n",
    "\n",
    "print(f\"Is valid: {is_valid}\")\n",
    "print(\"\\nExtracted metadata:\")\n",
    "print(json.dumps(extracted_metadata, indent=2))\n",
    "print(\"\\nClean text:\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Support\n",
    "\n",
    "EncypherAI provides support for streaming responses from LLMs. Let's see how to use the `StreamingHandler` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from encypher.streaming.handlers import StreamingHandler\n",
    "\n",
    "# Initialize streaming handler\n",
    "handler = StreamingHandler(\n",
    "    metadata={\n",
    "        \"model_id\": \"gpt-4\",\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"request_id\": \"req_12345\"\n",
    "    },\n",
    "    target=MetadataTarget.WHITESPACE,\n",
    "    encode_first_chunk_only=True  # Only encode the first chunk\n",
    ")\n",
    "\n",
    "# Simulate streaming chunks\n",
    "chunks = [\n",
    "    \"This is the first\",\n",
    "    \" chunk of a streaming\",\n",
    "    \" response from an LLM.\",\n",
    "    \" Metadata will be embedded\",\n",
    "    \" in the appropriate places.\"\n",
    "]\n",
    "\n",
    "# Process each chunk\n",
    "processed_chunks = []\n",
    "for chunk in chunks:\n",
    "    processed_chunk = handler.process_chunk(chunk)\n",
    "    processed_chunks.append(processed_chunk)\n",
    "    print(f\"Processed chunk: {processed_chunk}\")\n",
    "\n",
    "# Combine all chunks\n",
    "full_text = \"\".join(processed_chunks)\n",
    "print(\"\\nFull text:\")\n",
    "print(full_text)\n",
    "\n",
    "# Extract metadata from full text\n",
    "extracted_metadata = UnicodeMetadata.extract_metadata(full_text)\n",
    "print(\"\\nExtracted metadata:\")\n",
    "print(json.dumps(extracted_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with LiteLLM\n",
    "\n",
    "EncypherAI can be easily integrated with LiteLLM to work with various LLM providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Uncomment and run this cell if you have API keys configured\n",
    "\"\"\"\n",
    "import os\n",
    "import litellm\n",
    "\n",
    "# Set your API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"  # Replace with your actual key\n",
    "\n",
    "# Initialize streaming handler\n",
    "handler = StreamingHandler(\n",
    "    metadata={\n",
    "        \"model_id\": \"gpt-3.5-turbo\",\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"request_id\": \"req_12345\"\n",
    "    },\n",
    "    target=MetadataTarget.WHITESPACE\n",
    ")\n",
    "\n",
    "# Define messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a short paragraph about AI ethics.\"}\n",
    "]\n",
    "\n",
    "# Generate streaming response\n",
    "response = litellm.completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Process streaming chunks\n",
    "full_response = \"\"\n",
    "for chunk in response:\n",
    "    if hasattr(chunk.choices[0], 'delta') and hasattr(chunk.choices[0].delta, 'content'):\n",
    "        content = chunk.choices[0].delta.content\n",
    "        if content:\n",
    "            processed_chunk = handler.process_chunk(content)\n",
    "            full_response += processed_chunk\n",
    "            print(processed_chunk, end=\"\")\n",
    "\n",
    "print(\"\\n\\nExtracted metadata:\")\n",
    "print(json.dumps(UnicodeMetadata.extract_metadata(full_response), indent=2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the basic usage of EncypherAI for encoding and decoding metadata in text. EncypherAI provides a simple yet powerful way to embed invisible metadata in LLM-generated content, enabling provenance tracking, attribution, and verification.\n",
    "\n",
    "For more advanced usage and examples, please refer to the [EncypherAI documentation](https://docs.encypherai.com)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
